export default {
  common: {
    save: "保存",
    cancel: "取消",
    delete: "删除",
    edit: "编辑",
    create: "新增",
    add: "添加",
    enable: "启用",
    disable: "禁用",
    enabled: "已启用",
    disabled: "已禁用",
    loading: "加载中...",
    noData: "暂无数据",
    success: "操作成功",
    error: "操作失败",
    confirm: "确认",
    copy: "复制",
    test: "测试",
    import: "导入",
    export: "导出",
    search: "搜索",
    name: "名称",
    type: "类型",
    status: "状态",
    actions: "操作",
    back: "返回",
    close: "关闭",
    active: "激活",
    inactive: "未激活",
  },
  nav: {
    providers: "Providers",
    mcpServers: "MCP Servers",
    skills: "Skills",
    prompts: "Prompts",
    export: "导出",
    cliGuide: "命令手册",
    skillsGuide: "技能帮助",
    setupGuide: "环境配置",
    aiGlossary: "AI 技术",
    management: "管理",
    platform: "配置管理平台",
  },
  auth: {
    login: "登录",
    register: "注册",
    email: "邮箱",
    password: "密码",
    displayName: "显示名称",
    loginTitle: "登录您的账户",
    registerTitle: "创建新账户",
    switchToRegister: "没有账户？注册",
    switchToLogin: "已有账户？登录",
    registerSuccess: "注册成功，请查收确认邮件",
    loginSuccess: "登录成功",
    logout: "退出登录",
  },
  providers: {
    title: "Provider 管理",
    subtitle: "管理 AI CLI 的 API 配置",
    addProvider: "新增 Provider",
    editProvider: "编辑 Provider",
    empty: "暂无 Provider",
    emptyHint: "点击「新增 Provider」开始配置",
    providerName: "Provider 名称",
    providerType: "类型",
    appType: "应用",
    apiKey: "API Key",
    baseUrl: "Base URL",
    official: "官方登录",
    custom: "自定义",
    createSuccess: "创建成功",
    updateSuccess: "更新成功",
    deleteSuccess: "删除成功",
    copySuccess: "复制成功",
    testSuccess: "连接成功",
    testFailed: "连接失败",
    notSet: "未设置",
  },
  mcp: {
    title: "MCP Server 管理",
    subtitle: "统一管理 MCP 服务器配置",
    addServer: "新增 MCP Server",
    editServer: "编辑 MCP Server",
    empty: "暂无 MCP Server",
    emptyHint: "点击「新增 MCP Server」开始配置",
    serverName: "MCP Server 名称",
    transportType: "传输类型",
    command: "Command",
    arguments: "Arguments（空格分隔）",
    url: "URL",
    envVars: "环境变量",
    addEnvVar: "添加变量",
    appBindings: "绑定应用",
    createSuccess: "创建成功",
    updateSuccess: "更新成功",
    deleteSuccess: "删除成功",
    testPassed: "测试通过",
    testFailed: "测试失败",
  },
  skills: {
    title: "Skills 管理",
    subtitle: "管理 AI CLI 技能包",
    addRepo: "添加仓库",
    editRepo: "编辑仓库",
    repoOwner: "仓库所有者",
    repoName: "仓库名",
    branch: "分支",
    subdirectory: "子目录（可选）",
    isDefault: "默认仓库",
    scanSkills: "扫描 Skills",
    scanning: "扫描中...",
    installed: "已安装",
    notInstalled: "未安装",
    install: "安装",
    uninstall: "卸载",
    emptyRepos: "暂无仓库",
    emptyReposHint: "添加 GitHub 仓库来发现 Skills",
    emptySkills: "暂无 Skills",
    emptySkillsHint: "点击「扫描 Skills」从仓库发现技能包",
    scanSuccess: "扫描完成，发现 {count} 个 Skills",
    scanFailed: "扫描失败",
  },
  prompts: {
    title: "Prompts 管理",
    subtitle: "管理系统提示词预设与 AI 优化",
    addPrompt: "新增 Prompt",
    editPrompt: "编辑 Prompt",
    empty: "暂无 Prompt",
    emptyHint: "点击「新增 Prompt」开始创建提示词预设",
    promptName: "提示词名称",
    targetFile: "目标文件",
    content: "内容（Markdown）",
    editTab: "编辑",
    previewTab: "预览",
    setActive: "设为激活",
    activated: "激活",
    noContent: "（无内容）",
    createSuccess: "创建成功",
    updateSuccess: "更新成功",
    deleteSuccess: "删除成功",
    managementTab: "Prompts 管理",
    optimizerTab: "提示词优化器",
  },
  export: {
    title: "导出配置",
    subtitle: "将配置导出为各 CLI 工具官方格式文件",
    appExport: "按应用导出（ZIP）",
    appExportDesc: "严格按各 CLI 官方格式生成配置文件，打包为 ZIP 压缩包，解压后按指引路径放置即可使用",
    appExportHint: "下载 ZIP 后，将文件解压并按对应路径放置，CLI 工具下次启动时自动读取。Claude Code 的 Provider env 字段（API Key、Base URL、Model）已合并写入 settings.json，Codex 的 MCP 配置已内嵌于 config.toml。",
    dataBackup: "数据备份",
    dataBackupDesc: "备份应用内数据（用于跨账户迁移或恢复），不可直接用作 CLI 配置文件",
    fullBackup: "全量备份（ZIP）",
    backupDesc: "本备份格式仅用于在本应用内恢复数据，不可直接用作 CLI 配置文件",
    backupWarning: "备份文件仅用于在本应用内导入恢复，不是 CLI 原生格式，请勿直接放入 CLI 配置目录。",
    import: "导入配置",
    importDesc: "从 JSON 文件恢复数据，支持 Providers / MCP Servers / Prompts 格式",
    importHint: "支持导入 Providers、MCP Servers、Prompts 的 JSON 格式文件",
    deepLink: "Deep Link",
    deepLinkDesc: "生成分享链接用于快速导入 Provider 配置",
    exporting: "导出中...",
    exportSuccess: "导出成功",
    importSuccess: "导入成功，共导入 {count} 条记录",
    importFailed: "导入失败",
    selectFile: "选择文件",
    generateLink: "生成链接",
    copyLink: "复制链接",
    linkCopied: "链接已复制",
    providers: "Providers",
    mcpServers: "MCP Servers",
    skills: "Skills",
    prompts: "Prompts",
  },
  help: {
    title: "使用手册",
  },
  helpProviders: {
    what: "什么是 Provider？",
    whatDesc: "Provider 是 AI CLI 工具连接 AI 服务的 API 配置。平台支持为 Claude Code、Codex、Gemini CLI、OpenCode 等工具统一管理 Provider，每个 Provider 包含 API Key、Base URL、应用类型等信息。",
    whatTip: "一个应用可以配置多个 Provider，导出时将使用已启用且排序最前的 Provider。",
    types: "Provider 类型说明",
    typesDesc: "• Official Login：使用官方账号登录（如 Anthropic/OpenAI 账号），无需 API Key，仅适用于支持 OAuth 的应用\n• PackyCode：第三方 API 代理服务，需填写 PackyCode 平台提供的 API Key，Base URL 自动填充\n• Custom：完全自定义 API 端点，适合自建代理、中转服务或其他第三方 API 提供商",
    typesTip: "选择 Official Login 或 PackyCode 时，Base URL 会根据应用类型自动填充，无需手动输入。",
    howTo: "如何配置 Provider？",
    howToDesc: "1. 点击「新增 Provider」按钮，选择预设模板（Official Login / PackyCode / Custom）或手动填写\n2. 选择目标应用（Claude / Codex / Gemini / OpenCode）\n3. 填写 API Key（Official Login 类型可留空）\n4. 自定义类型需手动填写 Base URL\n5. 开关控制该 Provider 是否参与导出\n6. 可使用复制按钮快速克隆已有配置",
    test: "连接测试",
    testDesc: "点击卡片上的测试图标（闪电 / 信号图标），系统将向 API 端点发送探测请求，验证网络连通性和 API Key 有效性。\n\n• 绿色 ✓ — 连接成功，延迟时间一并显示\n• 红色 ✗ — 连接失败，会提示具体原因（如超时、401 无权限、网络不可达等）",
    testTip: "测试仅验证端点是否可达和 Key 是否有效，不会消耗 API 额度。Official Login 类型无法远程测试，请在本地 CLI 中验证。",
  },
  helpMcp: {
    what: "什么是 MCP Server？",
    whatDesc: "MCP（Model Context Protocol）Server 为 AI 工具提供额外能力扩展，如文件读写、网络请求、数据库查询、浏览器自动化等。通过配置 MCP Server，AI 工具可以调用外部服务完成更复杂的任务。",
    whatTip: "MCP 是 Anthropic 提出的开放协议，已被 Claude Code、Codex、Gemini CLI 等多个工具采用。",
    transport: "传输类型详解",
    transportDesc: "• Stdio（标准输入/输出）：通过本地命令启动进程，AI 工具与之通过 stdin/stdout 通信。适合大多数场景，如 npx 启动的 MCP 服务\n• HTTP：连接远程 HTTP 服务端点，适合已部署的云端 MCP 服务\n• SSE（Server-Sent Events）：通过服务端推送事件流通信，适合需要实时推送的场景",
    transportTip: "大多数 MCP Server 使用 Stdio 类型。如果是远程部署的服务，选择 HTTP 或 SSE。",
    templates: "内置模板库",
    templatesDesc: "平台提供 5 大分类的常用 MCP Server 一键配置模板：\n\n🌐 浏览器与测试：Playwright、Puppeteer 等\n🔍 搜索与网络：mcp-fetch、Brave Search、Context7 等\n💾 数据与存储：SQLite、PostgreSQL、文件系统、记忆存储等\n🛠️ 开发工具：GitHub、Sequential Thinking 等\n💬 协作通信：Slack 等\n\n点击模板名称即可一键创建对应的 MCP Server 配置。",
    templatesTip: "模板创建后仍可编辑所有字段。部分模板（如数据库类）需要修改路径参数才能正常使用。",
    env: "环境变量配置",
    envDesc: "为 MCP Server 设置运行时所需的环境变量，例如：\n• API Token / Secret Key — 用于身份认证\n• 文件路径 — 指定工作目录\n• 数据库连接串 — 指定数据源\n\n环境变量以键值对形式配置，支持多个变量。",
    envTip: "敏感信息（如 API Key）建议通过环境变量传递，避免硬编码在命令参数中。",
    bindings: "应用绑定机制",
    bindingsDesc: "每个 MCP Server 可以绑定到一个或多个目标应用（Claude / Codex / Gemini / OpenCode）。\n\n• 绑定的应用在「按应用导出」时会自动包含该 MCP Server 配置\n• 未绑定的应用导出时不会包含\n• 全量导出不受绑定影响，始终包含所有 MCP Server",
    bindingsTip: "如果一个 MCP Server 需要在多个工具中使用，勾选所有相关应用即可。",
  },
  helpSkills: {
    what: "什么是 Skills？",
    whatDesc: "Skills 是预定义的 AI 技能包，通常托管在 GitHub 仓库中。每个 Skill 包含特定领域的指令、上下文和最佳实践，帮助 AI 工具更好地完成特定类型的任务（如代码审查、单元测试生成、架构设计等）。",
    whatTip: "Skills 最初由 Anthropic 为 Claude Code 设计，本平台扩展支持管理来自任意 GitHub 仓库的 Skill。",
    repos: "仓库管理",
    reposDesc: "添加 GitHub 仓库作为 Skills 来源。每个仓库配置包含：\n• 所有者 + 仓库名 — 如 anthropics/skills\n• 分支 — 默认 main，可指定其他分支\n• 子目录 — 如果 Skills 不在仓库根目录，可指定子目录路径\n• 默认仓库标记 — 标记为默认的仓库会优先显示\n\n平台内置多个预设仓库分类（Skills 仓库、研发类、设计类、办公类等），点击即可快速添加。",
    reposTip: "添加私有仓库时，GitHub API 可能需要授权。公开仓库无需任何认证。",
    scan: "扫描与安装",
    scanDesc: "1. 添加仓库后，点击仓库卡片上的「扫描 Skills」按钮\n2. 系统通过 GitHub API 读取仓库目录结构，自动发现可用的 Skill（每个子目录视为一个 Skill）\n3. 系统还会尝试读取每个 Skill 目录下的 README.md 作为描述\n4. 发现的 Skill 显示在「Skills」标签页中\n5. 使用开关控制安装/卸载，已安装的 Skill 会在导出时自动包含",
    scanTip: "扫描基于 GitHub API，每小时有 60 次请求限制（未认证）。如果仓库较大，建议指定子目录缩小扫描范围。",
    views: "视图与筛选",
    viewsDesc: "Skills 列表支持两种视图模式：\n• 卡片视图 — 以网格形式展示，直观查看 Skill 名称和描述\n• 列表视图 — 以表格形式展示，信息更密集，适合大量 Skill 管理\n\n支持按名称/描述搜索、按安装状态筛选、按来源仓库筛选。",
  },
  helpPrompts: {
    what: "什么是 Prompts？",
    whatDesc: "Prompts 是系统提示词预设，用于指导 AI CLI 工具的行为和风格。不同的 AI 工具使用不同的配置文件来加载系统提示词，本平台统一管理这些提示词并支持按应用导出对应格式。",
    whatTip: "系统提示词决定了 AI 工具的行为偏好、编码风格、回复语言等，合理配置可以显著提升使用体验。",
    target: "目标文件映射",
    targetDesc: "每个 Prompt 需要选择一个目标文件，决定导出时生成的文件名：\n\n• CLAUDE.md → Claude Code — 放置在项目根目录，Claude Code 启动时自动加载\n• AGENTS.md → Codex — OpenAI Codex CLI 的系统提示词文件\n• GEMINI.md → Gemini CLI — Google Gemini CLI 的自定义指令文件\n• OPENCODE.md → OpenCode — OpenCode CLI 的提示词配置文件",
    targetTip: "CLAUDE.md 支持层级加载：项目根目录的全局生效，子目录中的仅在该目录下生效。",
    editor: "编辑器功能",
    editorDesc: "提示词内容使用 Markdown 格式编写，支持：\n• 标题层级（# ## ###）\n• 列表（有序/无序）\n• 代码块（行内和块级）\n• 强调（粗体/斜体）\n• 链接和引用\n\n切换到「预览」标签页可实时查看 Markdown 渲染效果。内容长度上限为 50,000 字符。",
    editorTip: "建议使用清晰的标题结构组织提示词内容，例如：# 角色定义 → # 编码规范 → # 输出格式。",
    active: "激活状态管理",
    activeDesc: "每个 Prompt 可以单独设置激活/停用状态：\n\n• 激活的 Prompt 在「按应用导出」时会自动作为该目标文件的内容\n• 同一目标文件可以有多个 Prompt，但建议只激活一个以避免冲突\n• 停用的 Prompt 不会被删除，可随时重新激活\n• 卡片上的开关可快速切换激活状态",
    activeTip: "可以为同一工具创建多个 Prompt（如「日常开发」「代码审查」「文档写作」），根据场景切换激活。",
    optimizer: "提示词优化器",
    optimizerDesc: "内置 AI 驱动的提示词优化功能，可以帮助您：\n• 分析现有提示词的结构和覆盖度\n• 自动优化措辞、补充遗漏的关键指令\n• 按照最佳实践模板重新组织内容\n• 支持对优化结果进行反馈和迭代",
    optimizerTip: "优化器基于业界最佳实践，但最终效果取决于您的具体使用场景，建议优化后仔细审阅再应用。",
  },
  helpExport: {
    what: "导出功能概览",
    whatDesc: "将平台配置导出为各 AI CLI 工具可直接使用的官方格式文件。按应用导出会生成标准 ZIP 包，解压后按路径放置即可使用。",
    whatTip: "按应用导出（ZIP）是推荐方式，生成的文件格式完全符合官方规范，可被 CLI 工具直接识别和加载。",
    app: "按应用导出（ZIP）",
    appDesc: "每个 CLI 工具生成一个 ZIP 包，内含所有必要配置文件：\n\n• Claude Code → settings.json（$schema + env{API Key/URL/Model} + permissions + mcpServers）+ CLAUDE.md + skills/\n  路径：将 settings.json 放置到 %USERPROFILE%\\.claude\\settings.json（Windows）或 ~/.claude/settings.json（macOS/Linux）\n\n• Codex CLI → config.toml（TOML 格式：顶层 model/api_key + [mcp_servers.name] 内嵌表格）+ AGENTS.md\n  路径：将 config.toml 放置到 %USERPROFILE%\\.codex\\config.toml（Windows）或 ~/.codex/config.toml（macOS/Linux）\n\n• Gemini CLI → settings.json（mcpServers）+ GEMINI.md\n  路径：将 settings.json 放置到 ~/.gemini/settings.json\n\n• OpenCode → config.json + OPENCODE.md\n\n仅导出：已启用的 Provider、已绑定该应用的 MCP Server、已激活的 Prompt、已安装的 Skills。",
    appTip: "导出前确认：目标应用的 Provider 已启用、MCP Server 已绑定、Prompt 已激活、Skills 已安装。\n\n重要提示：Claude Code 的 API Key（ANTHROPIC_AUTH_TOKEN）、Base URL（ANTHROPIC_BASE_URL）和模型名称直接写入 settings.json 的 env 字段，而非环境变量文件；Codex 的 MCP Servers 内嵌于 config.toml 的 [mcp_servers.name] 表格中，不再单独生成 mcp.json 或 config.yaml。",
    backup: "数据备份",
    backupDesc: "将所有模块的数据导出为 JSON（去除 id/user_id/时间戳等内部字段），用于：\n• 跨账户数据迁移\n• 数据备份与恢复\n• 在本应用内批量导入\n\n⚠️ 备份格式不是 CLI 原生配置格式，不可直接放入 CLI 配置目录。",
    backupTip: "通过「导入」功能可将备份数据恢复到本应用，适合换账户或多设备同步。",
    import: "导入配置",
    importDesc: "从 JSON 文件恢复数据，自动识别类型：\n• Providers — 含 provider_type 字段\n• MCP Servers — 含 transport_type 字段\n• Prompts — 含 target_file 字段\n\n导入为追加模式，不覆盖现有数据。",
    importTip: "导入文件必须是 JSON 数组格式，建议使用本应用的数据备份功能生成标准格式文件。",
    deepLink: "Deep Link 分享",
    deepLinkDesc: "生成包含已启用 Provider 配置的分享链接（不含 API Key），接收方可一键导入 Provider 模板。",
    deepLinkTip: "Deep Link 不含 API Key 等敏感信息，接收方需自行填写密钥。",
  },
  cliGuide: {
    title: "命令手册",
    subtitle: "Claude Code、Codex CLI、Gemini CLI 内置命令完整参考",
    searchPlaceholder: "搜索命令...",
    expandAll: "全部展开",
    collapseAll: "全部折叠",
    officialDocs: "官方文档",
    showing: "显示",
    total: "共",
    commands: "条命令",
    noResults: "未找到匹配的命令",
  },
  skillsGuide: {
    title: "技能使用帮助",
    subtitle: "Claude Code、Codex CLI、Gemini CLI Agent Skills 详细使用说明与配置手册",
    searchPlaceholder: "搜索技能说明...",
    expandAll: "全部展开",
    collapseAll: "全部折叠",
    officialDocs: "官方文档",
    showing: "显示",
    total: "共",
    items: "条说明",
    noResults: "未找到匹配的说明",
  },
  setupGuide: {
    title: "环境配置与常用技巧",
    subtitle: "Anthropic / Codex / Gemini CLI 环境搭建与最佳实践指南",
    searchPlaceholder: "搜索配置说明...",
    expandAll: "全部展开",
    collapseAll: "全部折叠",
    officialDocs: "官方文档",
    showing: "显示",
    total: "共",
    items: "条说明",
    noResults: "未找到匹配的说明",
  },
  aiGlossary: {
    title: "AI 前沿技术概览",
    subtitle: "大模型相关核心概念、前沿技术与主流模型分类全面解析",
    searchPlaceholder: "搜索技术概念...",
    expandAll: "全部展开",
    collapseAll: "全部折叠",
    showing: "显示",
    total: "共",
    items: "个概念",
    noResults: "未找到匹配的概念",
    tabs: {
      agentSystem: "Agent 体系",
      protocols: "协议与服务",
      methods: "技术方法",
      models: "主流模型",
    },
    agent: {
      title: "Agent（智能代理）",
      subtitle: "自主决策的 AI 实体",
      definition: "定义与介绍",
      definitionContent: "Agent 是基于大语言模型（LLM）的自主决策实体，具备感知环境、推理分析和执行行动的能力。它通过接收用户指令或环境信号，自主规划任务步骤，调用工具完成目标，并根据反馈迭代优化。Agent 的核心在于「自主性」——无需人类逐步指导即可完成复杂的多步任务。",
      function: "作用/功能",
      functionContent: "Agent 解决了传统 LLM「一问一答」模式的局限。它能够：\n• 自主分解复杂任务为多个子步骤\n• 动态调用外部工具（文件系统、API、数据库等）\n• 基于执行结果进行反思和自我纠错\n• 维护任务上下文，跨多轮交互保持一致性",
      scenario: "应用场景",
      scenarioContent: "• 代码开发助手：如 Claude Code、Codex CLI、Cursor Agent，能自主阅读代码库、编写代码、运行测试\n• 客服自动化：理解用户问题，查询知识库，执行工单操作\n• 数据分析：自主编写 SQL 查询、生成可视化图表、撰写分析报告\n• 研究助手：检索文献、总结论文、生成研究综述",
      relation: "相互关系",
      relationContent: "Agent 是整个 AI Agent 体系的基础单元。它与其他概念的关系：\n• 是 Sub-Agent 和 Agent Team 的组成基础\n• 通过加载 Skills 扩展专业领域能力\n• 通过 MCP 协议调用外部工具和服务\n• 通过 ACP 协议与其他 Agent 通信协作\n• 其行为由 Prompt Engineering 驱动和定义\n• 在 Workflow 中作为执行节点被编排调度",
    },
    subAgent: {
      title: "Sub-Agent（子代理）",
      subtitle: "专注执行子任务的派生代理",
      definition: "定义与介绍",
      definitionContent: "Sub-Agent 是由主 Agent 动态创建的专注型代理，专门负责执行特定子任务。主 Agent 将复杂任务分解后，为每个子任务派生一个 Sub-Agent，每个 Sub-Agent 拥有独立的上下文和工具访问权限，完成后将结果返回给主 Agent 汇总。这种机制类似于编程中的「fork」操作。",
      function: "作用/功能",
      functionContent: "Sub-Agent 解决了单个 Agent 处理复杂任务时的能力瓶颈：\n• 任务分解与并行处理：多个子任务可同时执行，显著提升效率\n• 降低复杂度：每个 Sub-Agent 只需关注单一子任务，减少上下文混淆\n• 隔离风险：子任务失败不影响其他并行任务\n• 专业化处理：不同 Sub-Agent 可加载不同的 Skills 和工具",
      scenario: "应用场景",
      scenarioContent: "• Claude Code 的 context: fork 功能：主 Agent 派生 Sub-Agent 并行编辑多个文件\n• 多文件代码重构：分别处理不同模块的代码修改\n• 并行测试执行：同时运行多个测试套件\n• 文档批量处理：并行翻译、校对、格式化多个文档",
      relation: "相互关系",
      relationContent: "Sub-Agent 在 Agent 体系中扮演「执行者」角色：\n• 由 Agent 创建、调度和管理生命周期\n• 多个 Sub-Agent 可组成 Agent Team 协作\n• 通过 Workflow 编排多个 Sub-Agent 的执行顺序和依赖关系\n• 可独立加载 Skills 获取专业能力\n• 执行结果汇总给主 Agent 进行最终决策",
    },
    agentTeam: {
      title: "Agent Team（代理团队）",
      subtitle: "多 Agent 协作的团队架构",
      definition: "定义与介绍",
      definitionContent: "Agent Team 是多个 Agent 组成的协作团队架构，每个 Agent 承担特定角色（如架构师、开发者、测试员、审核者），通过预定义的协作流程共同完成复杂任务。团队中的 Agent 既可以是独立的主 Agent，也可以是 Sub-Agent，关键在于角色分工和通信机制。",
      function: "作用/功能",
      functionContent: "Agent Team 解决了单 Agent 难以胜任的大型复杂任务：\n• 角色专业化：每个 Agent 专注于自己擅长的领域\n• 多视角审查：不同角色从不同角度检查工作质量\n• 流水线协作：前一个 Agent 的输出作为后一个的输入\n• 扩展性：通过增加团队成员应对更大规模的任务",
      scenario: "应用场景",
      scenarioContent: "• 软件开发团队：架构师 Agent 设计方案 → 开发者 Agent 编写代码 → 测试员 Agent 编写测试 → 审核者 Agent 代码审查\n• 研究团队：文献检索 Agent → 数据分析 Agent → 论文撰写 Agent\n• 内容创作团队：策划 Agent → 写作 Agent → 编辑 Agent → 发布 Agent\n• DevOps 团队：监控 Agent → 诊断 Agent → 修复 Agent → 验证 Agent",
      relation: "相互关系",
      relationContent: "Agent Team 是 Agent 体系的高级协作模式：\n• 由多个 Agent 和/或 Sub-Agent 组成\n• 通过 ACP 协议实现团队成员间的通信和协调\n• 使用 Workflow 定义团队的协作流程和任务分配\n• 团队中的每个 Agent 可各自加载不同的 Skills\n• 团队整体通过 MCP Server 访问共享的外部资源",
    },
    skills: {
      title: "Skills（智能代理技能）",
      subtitle: "可复用的 Agent 能力扩展包",
      definition: "定义与介绍",
      definitionContent: "Skills 是预定义的、可复用的能力包，用于扩展 Agent 的专业领域知识和行为模式。每个 Skill 包含特定领域的指令、上下文信息、最佳实践和约束条件，Agent 加载 Skill 后即可获得相应的专业能力。Skills 实现了 Agent 能力的模块化和渐进式披露。",
      function: "作用/功能",
      functionContent: "Skills 提供了 Agent 能力的标准化扩展机制：\n• 模块化复用：一次编写，多处使用，避免重复定义\n• 渐进式披露：按需加载，避免上下文过载\n• 领域专业化：将专家知识封装为可分发的包\n• 版本管理：通过 Git 仓库管理 Skill 的版本迭代\n• 社区共享：开发者可以共享和复用他人的 Skills",
      scenario: "应用场景",
      scenarioContent: "• Claude Code Skills：通过 /install-skill 安装社区 Skill，扩展代码审查、测试生成等能力\n• Codex Skills：自定义指令集，指导 Codex 的编码风格和规范\n• Gemini Skills：配置特定场景下的行为偏好和专业知识\n• 企业内部 Skills：封装团队的编码规范、架构模式、安全策略",
      relation: "相互关系",
      relationContent: "Skills 是 Agent 能力体系的扩展层：\n• 被 Agent 按需加载和调用，扩展 Agent 的专业能力\n• 可通过 MCP Server 提供更底层的外部工具能力\n• Skills 的内容本质上是精心设计的 Prompt Engineering 产物\n• 在 Agent Team 中，不同 Agent 可加载不同 Skills 实现角色分工\n• Skills 仓库通过 Git 进行版本管理和分发",
    },
    mcp: {
      title: "MCP Servers（模型上下文协议服务器）",
      subtitle: "标准化的 Agent 工具调用接口",
      definition: "定义与介绍",
      definitionContent: "MCP（Model Context Protocol）是 Anthropic 提出的开放协议标准，MCP Server 是该协议的服务端实现。它为 Agent 提供了标准化的外部工具调用接口，使 Agent 能够以统一的方式访问文件系统、数据库、API、浏览器等外部资源。MCP 采用客户端-服务器架构，支持 Stdio、HTTP、SSE 三种传输方式。",
      function: "作用/功能",
      functionContent: "MCP Server 解决了 Agent 与外部世界交互的标准化问题：\n• 统一接口：不同工具和服务通过统一协议暴露能力\n• 即插即用：Agent 无需了解工具内部实现，通过 MCP 协议即可调用\n• 安全隔离：MCP Server 在独立进程中运行，与 Agent 隔离\n• 生态扩展：任何人都可以开发和发布 MCP Server\n• 跨平台兼容：Claude Code、Codex、Gemini CLI 等均支持 MCP",
      scenario: "应用场景",
      scenarioContent: "• 文件系统操作：读写文件、搜索文件、监控文件变化\n• 数据库查询：连接 PostgreSQL、SQLite、MongoDB 等数据库\n• 浏览器自动化：Playwright、Puppeteer 驱动的网页操作\n• API 集成：GitHub、Slack、JIRA 等第三方服务对接\n• 搜索服务：Brave Search、Google Search 等搜索引擎接入\n• 知识检索：连接 RAG 系统提供知识库查询能力",
      relation: "相互关系",
      relationContent: "MCP Server 是 Agent 工具生态的基础设施：\n• 被 Agent 通过 MCP 协议调用，提供外部工具能力\n• 与 ACP 协议互补——MCP 负责 Agent 与工具的通信，ACP 负责 Agent 间的通信\n• 可作为 Skills 的底层能力提供者（Skills 封装高层知识，MCP 提供底层工具）\n• RAG 系统可通过 MCP Server 暴露检索能力\n• 在 Workflow 中作为工具节点被编排调用",
    },
    acp: {
      title: "ACP（Agent 通信协议）",
      subtitle: "Agent 间标准化通信协议",
      definition: "定义与介绍",
      definitionContent: "ACP（Agent Communication Protocol）是为多 Agent 系统设计的标准化通信协议，定义了 Agent 之间发现、协商、消息传递和协作的规范。ACP 使不同平台、不同开发者构建的 Agent 能够相互识别和协作，类似于互联网中的 HTTP 协议为 Web 应用提供的通信标准。",
      function: "作用/功能",
      functionContent: "ACP 解决了多 Agent 系统中的互操作性问题：\n• Agent 发现：让 Agent 能够发现其他可用的 Agent 及其能力\n• 能力协商：Agent 之间协商谁来完成什么任务\n• 消息传递：定义 Agent 间通信的消息格式和语义\n• 状态同步：保持多个 Agent 之间的状态一致性\n• 跨平台互操作：不同框架构建的 Agent 可以无缝协作",
      scenario: "应用场景",
      scenarioContent: "• 跨平台 Agent 互操作：让 Claude Agent 与 GPT Agent 协作完成任务\n• Agent 市场/商店：发布和发现可用的 Agent 服务\n• 企业级多 Agent 编排：不同部门的 Agent 通过 ACP 协调工作\n• 联邦学习协作：多个 Agent 在保护数据隐私的前提下协作训练",
      relation: "相互关系",
      relationContent: "ACP 是多 Agent 协作的通信基础：\n• 为 Agent Team 提供成员间的通信和协调机制\n• 与 MCP 协议互补——MCP 管理 Agent 与工具的通信，ACP 管理 Agent 间的通信\n• 在 Workflow 中支持跨 Agent 的任务传递和状态同步\n• 使不同 Skills 配置的 Agent 能够相互理解和协作",
    },
    lsp: {
      title: "LSP（语言服务协议）",
      subtitle: "AI 场景的代码理解能力",
      definition: "定义与介绍",
      definitionContent: "LSP（Language Server Protocol）最初由 Microsoft 为 IDE 设计，用于提供代码补全、跳转定义、错误诊断等语言服务。在 AI Agent 场景中，LSP 被扩展应用为 Agent 的「代码理解引擎」，使 Agent 能够像人类开发者一样理解代码结构、符号关系和类型系统，而不仅仅是将代码作为文本处理。",
      function: "作用/功能",
      functionContent: "LSP 为 AI Agent 提供了结构化的代码理解能力：\n• 符号解析：理解变量、函数、类的定义和引用关系\n• 类型推断：获取表达式的类型信息，减少类型错误\n• 跳转定义：追踪符号到其定义位置，理解代码依赖\n• 错误诊断：实时发现语法和类型错误\n• 代码补全：基于上下文提供智能补全建议\n• 重构支持：安全地执行重命名、提取方法等重构操作",
      scenario: "应用场景",
      scenarioContent: "• AI 编码助手的代码分析：Claude Code 使用 LSP 理解项目代码结构\n• 智能重构：Agent 基于 LSP 信息执行安全的跨文件重构\n• 代码审查：利用 LSP 的诊断能力发现潜在问题\n• 项目导航：Agent 通过 LSP 快速定位相关代码，提高上下文获取效率",
      relation: "相互关系",
      relationContent: "LSP 增强了 Agent 在代码领域的专业能力：\n• 为 Agent 提供结构化的代码理解能力，超越纯文本分析\n• 被 Skills 利用——代码相关的 Skills 依赖 LSP 提供的代码分析信息\n• 可通过 MCP Server 暴露 LSP 能力，使远程 Agent 也能使用\n• 提升 Prompt Engineering 的效果——结合 LSP 信息的 Prompt 更精准",
    },
    rag: {
      title: "RAG（检索增强生成）",
      subtitle: "外部知识增强的 LLM 输出",
      definition: "定义与介绍",
      definitionContent: "RAG（Retrieval-Augmented Generation，检索增强生成）是一种将外部知识检索与 LLM 生成相结合的技术架构。RAG 系统先从外部知识库（文档、数据库、向量存储等）中检索与查询相关的信息片段，然后将这些信息作为上下文注入 LLM 的提示中，使模型基于最新、最准确的信息生成回答。",
      function: "作用/功能",
      functionContent: "RAG 解决了 LLM 的两大核心问题：\n• 知识截止：LLM 训练数据有时效性，RAG 提供实时知识更新\n• 幻觉问题：LLM 可能生成虚假信息，RAG 通过引用真实文档降低幻觉率\n• 领域适配：无需微调模型，通过更换知识库即可适配不同领域\n• 可追溯性：生成的回答可以引用具体来源，增强可信度\n• 成本效率：相比微调模型，RAG 的知识更新成本更低",
      scenario: "应用场景",
      scenarioContent: "• 企业知识库问答：基于内部文档回答员工问题\n• 客服系统：检索产品文档和FAQ，提供准确的客户支持\n• 法律助手：检索法律条文和案例，辅助法律分析\n• 代码助手：检索代码库和技术文档，辅助开发\n• 实时信息查询：检索最新新闻、市场数据等时效性信息",
      relation: "相互关系",
      relationContent: "RAG 是 Agent 知识获取的重要机制：\n• 可作为 MCP Server 暴露检索能力，供 Agent 调用\n• 增强 Agent 的知识获取能力，解决 LLM 知识截止问题\n• 在 Workflow 中作为知识检索节点，为后续步骤提供信息\n• 与 Prompt Engineering 配合——检索结果通过 Prompt 模板注入 LLM\n• 可为 Skills 提供动态知识支持，使 Skills 的内容不局限于静态定义",
    },
    workflow: {
      title: "Workflow（工作流）",
      subtitle: "预定义的任务执行流程编排",
      definition: "定义与介绍",
      definitionContent: "Workflow（工作流）是预定义的任务执行流程编排系统，将复杂任务拆解为有序的步骤序列，定义步骤间的执行顺序、条件分支、并行/串行关系和数据流向。在 AI Agent 场景中，Workflow 用于编排 Agent、Sub-Agent 和工具的执行，确保任务按照预期流程完成。",
      function: "作用/功能",
      functionContent: "Workflow 提供了任务执行的确定性和可控性：\n• 流程标准化：将最佳实践固化为可复用的流程模板\n• 执行可控：明确每一步做什么、谁来做、何时做\n• 条件分支：根据中间结果动态调整后续步骤\n• 错误处理：定义失败重试、回退和补偿机制\n• 可观测性：追踪每个步骤的执行状态和结果\n• 并行编排：合理安排并行和串行步骤，优化执行效率",
      scenario: "应用场景",
      scenarioContent: "• CI/CD 自动化：代码提交 → 构建 → 测试 → 部署的自动化流水线\n• 多步数据处理：数据采集 → 清洗 → 分析 → 可视化\n• 审批流程：请求提交 → 初审 → 复审 → 执行\n• Agent 编排：规划 Agent → 执行 Agent → 审查 Agent 的串行协作\n• 内容生产：选题 → 写作 → 编辑 → 审核 → 发布",
      relation: "相互关系",
      relationContent: "Workflow 是 Agent 系统的执行编排层：\n• 编排 Agent 和 Sub-Agent 的执行顺序和依赖关系\n• 定义 Agent Team 的协作流程和角色交互方式\n• 可内嵌 Prompt 模板，为每个步骤定义 Agent 的行为指令\n• 通过 MCP Server 调用外部工具作为流程中的节点\n• 与 ACP 协作，实现跨 Agent 的任务传递",
    },
    prompt: {
      title: "Prompt Engineering（提示词工程）",
      subtitle: "设计和优化 LLM 输入提示的方法论",
      definition: "定义与介绍",
      definitionContent: "Prompt Engineering（提示词工程）是设计、优化和迭代 LLM 输入提示的系统化方法论。它研究如何通过精心构造的提示，引导 LLM 产生高质量、可控、符合预期的输出。Prompt Engineering 涵盖了从简单的指令设计到复杂的系统提示架构，是 AI 应用开发的核心技能。",
      function: "作用/功能",
      functionContent: "Prompt Engineering 是控制 LLM 行为的核心手段：\n• 行为定义：通过系统提示定义 Agent 的角色、能力和约束\n• 输出控制：规范 LLM 的输出格式、风格和内容边界\n• 推理引导：使用思维链（CoT）等技术提升推理质量\n• Few-shot 学习：通过示例教会 LLM 新的任务模式\n• 安全防护：设计防注入和越界防护的提示策略",
      scenario: "应用场景",
      scenarioContent: "• CLAUDE.md 系统提示：为 Claude Code 定义项目级别的行为规范和编码标准\n• AGENTS.md：为 Codex CLI 配置系统指令和工作模式\n• Few-shot 示例：通过输入-输出示例教会模型特定任务\n• 思维链（Chain of Thought）：引导模型逐步推理复杂问题\n• 提示词模板：标准化的提示结构，支持变量插入和动态组装",
      relation: "相互关系",
      relationContent: "Prompt Engineering 是 AI Agent 体系的基础方法论：\n• 是 Skills 内容编写的基础——每个 Skill 本质上是精心设计的 Prompt\n• Workflow 中嵌入 Prompt 模板，为每个步骤定义 Agent 行为\n• Agent 的所有行为最终由 Prompt 驱动和定义\n• 与 RAG 配合——检索结果通过 Prompt 模板注入上下文\n• 影响 Agent 通过 MCP 和 ACP 协议交互的方式和策略",
    },
    anthropic: {
      title: "Anthropic Claude 系列",
      subtitle: "以安全性和长上下文见长的旗舰模型",
      definition: "模型家族概述",
      definitionContent: "Anthropic 的 Claude 系列专注于 AI 安全与可解释性，采用 Constitutional AI 训练方法。主要产品线：\n\n• Claude 3.5 Sonnet — 当前旗舰，代码能力顶尖，平衡速度与性能，支持 200K token 上下文\n• Claude 3.5 Haiku — 快速经济型，适合高并发场景，仍具备强大代码能力\n• Claude 3 Opus — 最高推理能力，适合复杂分析和长文本任务\n• Claude 3 Sonnet / Haiku — 上一代产品线，性价比导向",
      function: "核心能力",
      functionContent: "• 超长上下文：标准 200K tokens，支持整个代码仓库或长文档分析\n• 代码能力：SWE-bench 排名领先，Claude Code 的基础模型\n• 多模态：支持图像、PDF、文档分析\n• 工具使用：强大的 Function Calling / Tool Use 能力，是 MCP 协议的原生支持者\n• 安全性：RLHF + Constitutional AI，拒绝率和有害内容过滤业界领先",
      scenario: "典型使用场景",
      scenarioContent: "• Claude Code — 官方 AI 编程助手，深度集成 claude-3-5-sonnet\n• 长文档分析：法律合同、学术论文、代码审查\n• Agent 构建：MCP 协议的推动者，适合构建工具密集型 Agent\n• 内容创作：技术文章、营销文案、多语言翻译",
      relation: "与其他生态关系",
      relationContent: "• 是 MCP 协议的发起方，Claude Code/Gemini CLI/Codex 均支持 MCP\n• claude-3-5-sonnet 是本平台默认支持的 Claude Code Provider 目标模型\n• Anthropic API 兼容 OpenAI 接口格式，多数中转代理（如 Kimi、PackyCode）均适配",
    },
    openai: {
      title: "OpenAI GPT / o 系列",
      subtitle: "最广泛采用的通用大模型",
      definition: "模型家族概述",
      definitionContent: "OpenAI 是大模型领域的先驱，产品线分为两大类：\n\n【GPT 系列（生成式）】\n• GPT-4o — 多模态旗舰，支持实时音视频，推理强，速度快\n• GPT-4o mini — 轻量经济型，适合高并发低延迟场景\n• GPT-4 Turbo — 128K 上下文，知识截止 2024 年\n• GPT-3.5 Turbo — 经济型入门，适合简单任务\n\n【o 系列（推理增强型）】\n• o3 — 最新旗舰推理模型，数学/代码/科学顶尖\n• o3-mini — 轻量推理，速度更快，适合编程任务\n• o1 — 首代推理模型，支持扩展思考（extended thinking）\n• o1-mini — 轻量版 o1",
      function: "核心能力",
      functionContent: "• GPT 系列：通用推理、多模态（文本/图像/音频/视频）、长上下文\n• o 系列：慢思考（chain-of-thought）、数学证明、代码竞赛级能力\n• Function Calling：业界最成熟的工具调用 API\n• Structured Outputs：JSON 模式保证结构化输出\n• Assistants API：内置线程、文件、工具管理\n• Codex 模型：OpenAI Codex CLI 的底层模型（o4-mini / o3-mini）",
      scenario: "典型使用场景",
      scenarioContent: "• Codex CLI 的默认底层模型（o4-mini）\n• 复杂推理和数学：o3/o1 系列用于数学竞赛、科学研究\n• 通用问答和写作：GPT-4o 用于日常助手\n• 代码生成：GPT-4o / o3-mini 是主流选择\n• 企业级集成：Azure OpenAI 服务，合规部署",
      relation: "与其他生态关系",
      relationContent: "• OpenAI API 是行业事实标准，大多数第三方代理（PackyCode、Kimi 等）均兼容其接口\n• Codex CLI 默认使用 o4-mini 模型\n• 本平台支持将 OpenAI 兼容接口配置为自定义 Provider",
    },
    google: {
      title: "Google Gemini 系列",
      subtitle: "原生多模态、超长上下文的 Google 旗舰",
      definition: "模型家族概述",
      definitionContent: "Google DeepMind 的 Gemini 系列是真正从设计之初就支持多模态的大模型：\n\n• Gemini 2.5 Pro — 最新旗舰，拥有 100 万 token 超长上下文（实验版支持 200 万），推理能力大幅提升\n• Gemini 2.5 Flash — 高速版旗舰，速度/价格领先，适合高并发\n• Gemini 2.0 Flash — 上一代速度王，稳定生产就绪\n• Gemini 1.5 Pro / Flash — 第三方代理仍广泛使用的版本\n• Gemini Nano — 端侧部署的轻量模型（Android / Chrome）",
      function: "核心能力",
      functionContent: "• 超长上下文：100 万 tokens，可分析整个代码仓库或长视频\n• 原生多模态：文本、图像、音频、视频、PDF 统一处理\n• Google Search 集成：内置实时搜索增强（Grounding）\n• 代码能力：Gemini 2.5 Pro 在 LiveBench 代码基准接近 Claude 3.5 Sonnet\n• Google Workspace 集成：与 Docs/Sheets/Gmail 深度集成",
      scenario: "典型使用场景",
      scenarioContent: "• Gemini CLI 的底层模型\n• 超长文档分析：视频理解、多文档对比\n• Google 生态集成：Workspace 智能助手\n• 多模态任务：图表解读、代码截图分析\n• 实时搜索增强型问答",
      relation: "与其他生态关系",
      relationContent: "• Gemini CLI 的官方默认模型\n• 本平台 Gemini CLI Provider 对应 Google AI Studio API 或 Vertex AI\n• 通过 GOOGLE_API_KEY / GEMINI_API_KEY 环境变量配置（不写入 settings.json）",
    },
    meta: {
      title: "Meta Llama 系列",
      subtitle: "最具影响力的开源大模型",
      definition: "模型家族概述",
      definitionContent: "Meta 的 Llama 系列是目前最重要的开源大模型家族，推动了整个开源 AI 生态：\n\n• Llama 3.3 70B — 当前最佳开源模型之一，接近 GPT-4o 水平\n• Llama 3.1 405B — 超大参数量，对标 GPT-4\n• Llama 3.2 — 多模态版本，支持图像理解，有 1B/3B 轻量版\n• Llama 3.1 8B / 70B — 最广泛部署的版本\n• Code Llama — 针对代码优化的衍生版本",
      function: "核心能力",
      functionContent: "• 完全开源：权重可商用下载，支持本地部署\n• 微调友好：LoRA / QLoRA 微调成本极低\n• 工具调用：3.1+ 版本支持 Function Calling\n• 多尺寸选择：1B 到 405B 全覆盖，适配不同硬件\n• 活跃社区：Ollama、LM Studio、vLLM 等大量工具支持",
      scenario: "典型使用场景",
      scenarioContent: "• 本地私有部署：Ollama + Llama 3.1 8B，完全离线运行\n• 企业私有化：数据不出内网，符合合规要求\n• 微调定制：在特定领域数据上微调，打造专业模型\n• 开发者研究：学习大模型原理和实验",
      relation: "与其他生态关系",
      relationContent: "• 可通过 Ollama 在本地运行，配合 OpenAI 兼容接口接入本平台\n• Groq 等推理加速服务提供 Llama API 访问\n• 许多第三方代理（如 Together AI、Perplexity）提供 Llama API",
    },
    chinese: {
      title: "中国主流大模型",
      subtitle: "国产头部大模型产品线对比",
      definition: "主要厂商概述",
      definitionContent: "中国大模型生态快速发展，涌现出多个具有全球竞争力的产品：\n\n【阿里 Qwen（通义）系列】\n• Qwen2.5 — 旗舰版，72B 参数，代码和数学能力突出\n• Qwen2.5-Coder — 专业代码模型\n• Qwen-Long — 超长上下文版本\n\n【DeepSeek 系列】\n• DeepSeek-R1 — 推理能力对标 o1，完全开源\n• DeepSeek-V3 — 通用旗舰，极高性价比\n• DeepSeek-Coder-V2 — 代码专精版\n\n【Kimi（月之暗面）系列】\n• kimi-for-coding — Claude Code / Codex 兼容代理，本平台内置模板\n• Moonshot v1 — 通用模型\n\n【其他】\n• 百度文心 4.0、智谱 GLM-4、MiniMax-Text-01 等",
      function: "核心优势",
      functionContent: "• 价格优势：多数国产模型 API 价格远低于 OpenAI\n• 中文能力：在中文理解、生成和文化适配上表现出色\n• 开源生态：DeepSeek-R1、Qwen2.5 等完全开源，支持本地部署\n• 合规友好：数据存储在国内，满足数据主权要求\n• 兼容性：多数提供 OpenAI 兼容接口，便于迁移",
      scenario: "典型使用场景",
      scenarioContent: "• kimi-for-coding：直接替代 Claude API，用于 Claude Code 本地开发\n• DeepSeek-V3：高性价比通用任务，支持 Function Calling\n• Qwen2.5-Coder：代码生成和审查，中文注释友好\n• 企业私有化：Qwen / DeepSeek 本地部署，数据不出境",
      relation: "与本平台关系",
      relationContent: "• 本平台内置 PackyCode Provider 模板，支持 kimi-for-coding 等兼容接口\n• 可将任意 OpenAI 兼容的国产模型 API 配置为自定义 Provider\n• 导出的 settings.json 的 env.ANTHROPIC_BASE_URL 可指向国产代理地址",
    },
    specialized: {
      title: "专用与前沿模型",
      subtitle: "垂直领域与新兴架构的代表模型",
      definition: "分类概述",
      definitionContent: "除通用大模型外，还有一批针对特定领域或采用新型架构的前沿模型：\n\n【代码专精模型】\n• GitHub Copilot（GPT-4o 驱动）— 最广泛使用的代码补全工具\n• StarCoder2 — Hugging Face 开源代码模型\n• CodeGemma — Google 面向代码的轻量模型\n\n【多模态前沿】\n• GPT-4o（实时模式）— 实时语音+视频+文本交互\n• Gemini 2.5 Pro — 支持 200 万 token 和视频理解\n• Claude 3.5 Sonnet — 计算机操作（Computer Use）能力\n\n【推理增强型】\n• OpenAI o3 / o1 — Chain-of-Thought 自动推理\n• DeepSeek-R1 — 开源推理模型\n• QwQ-32B — Qwen 系列推理增强版\n\n【小型高效模型】\n• Phi-4（Microsoft）— 140 亿参数，推理能力超越更大模型\n• Gemma 2（Google）— 9B/27B，开源精品\n• Mistral Nemo — 12B 开源多语言模型",
      function: "选型指南",
      functionContent: "如何根据场景选择合适的模型：\n\n• 需要最强推理/数学 → OpenAI o3 / DeepSeek-R1\n• 最强代码能力 → Claude 3.5 Sonnet / GPT-4o\n• 超长文档处理 → Gemini 2.5 Pro（100 万+ tokens）\n• 本地私有部署 → Llama 3.1 8B / Qwen2.5 7B / Mistral Nemo\n• 最低成本 API → DeepSeek-V3 / Gemini 2.0 Flash / Qwen2.5\n• 中文最优 → Qwen2.5 / DeepSeek-V3 / Kimi\n• CLI 编程助手 → Claude Code（Sonnet）/ Codex（o4-mini）",
      scenario: "前沿趋势",
      scenarioContent: "• 多模态融合：文本/图像/音频/视频统一模型成为标配\n• 推理模型崛起：o3/R1 类思维链模型在复杂任务大幅超越传统模型\n• 小模型精品化：Phi-4、Gemma 2 等证明小参数也能高性能\n• 开源追平闭源：Llama 3.3、DeepSeek-V3 已接近 GPT-4 级别\n• Agent 原生设计：新模型越来越重视 Tool Use、长上下文、稳定 JSON 输出",
      relation: "生态兼容性",
      relationContent: "• 大多数模型提供 OpenAI 兼容 API，可直接配置为本平台 Custom Provider\n• 推荐通过 Ollama（本地）或 OpenRouter（云端聚合）接入多种模型\n• Claude Code 通过 ANTHROPIC_BASE_URL 支持任意兼容代理\n• Codex CLI 通过 config.toml 的 provider_base_url 支持自定义端点",
    },
  },
  theme: {
    light: "浅色",
    dark: "深色",
    system: "跟随系统",
  },
};
